# Artifact Appendix

Paper title: **Word-level Annotation of GDPR Transparency Compliance in Privacy Policies using Large Language Models**

Requested Badge(s):
  - [X] **Available**
  - [ ] **Functional**
  - [ ] **Reproduced**

## Description

This artifact relates to the paper "Word-level Annotation of GDPR Transparency Compliance in Privacy Policies using Large Language Models", accepted to PoPETs 2026.1.

Authors: Thomas Cory, Wolf Rieder, Julia Krämer, Philip Raschke, Patrick Herbke, and Axel Küpper.

The artifact contains the code of the LLM-based annotation pipeline presented in the paper, as well as the "GDPR Transparency 200" dataset used in the evaluation. The code allows to reproduce the results presented in the paper, and can be used to annotate new privacy policies with GDPR transparency requirements.

### Security/Privacy Issues and Ethical Concerns

This artifact does not pose any security risks as it does not disable any security mechanisms, nor does it run any vulnerable code.

The dataset included in the artifact contains the verbatim text content of 200 publicly available privacy policies of Android applications. These privacy policies were collected in December 2024 by crawling the links to the privacy policies provided in the Google Play Store.

The privacy policies are publicly available documents, and their use for research purposes is generally considered acceptable. However, the authors have not sought explicit permission from the app developers to include their privacy policies in this dataset. The privacy policies may contain references to personal data collected by the apps, as well as contact information of the app developers. The authors have taken care to ensure that no personal data of users is included in the dataset.

## Environment

This project directory is structured as follows:

```
project/
│
├── main.py
├── requirements.txt
├── .env
├── dataset/
├── src/
└── output/
```

- **`main.py`**: Entry point of the application.
- **`requirements.txt`**: Lists the Python dependencies required for the project.
- **`.env`**: Environment file containing API keys. This file is not and should never be committed to version control!
- **`dataset/`**: Directory containing the GDPR Transparency 200 dataset, comprising 200 privacy policies with manually curated annotations.
- **`src/`**: Directory containing the source code for the project.
- **`output/`**: Directory where the output files are be saved (generated by the pipeline).

### Prerequisites

Before running the project, ensure you have the following installed:

- Python 3.7 or higher
- Required Python packages listed in `requirements.txt` (if any)

You can install the necessary Python packages by running:

```bash
pip install -r requirements.txt
```

To set up a virtual environment, you can use `venv`:

```bash
python -m venv venv
source env/bin/activate
pip install -r requirements.txt
```

## Running the Project

To run the project, execute the `main.py` script from the command line. The script requires a run ID and default model to be provided and supports multiple optional arguments to customize the execution.

### LLM API Key

The pipeline supports multiple LLM providers: Ollama, OpenAI, Anthropic, and DeepSeek. Depending on your chosen LLM provider, you need to set up the corresponding API key in a `.env` file in the project directory.

**For OpenAI:**
```
OPENAI_API_KEY=your-openai-api-key-here
```

**For Anthropic:**
```
ANTHROPIC_API_KEY=your-anthropic-api-key-here
```

**For DeepSeek:**
```
DEEPSEEK_API_KEY=your-deepseek-api-key-here
```

**For Ollama (local deployment):**
```
OLLAMA_API_KEY=your-ollama-api-key-here
```

You only need to provide the API key for the LLM provider(s) you intend to use. The pipeline will automatically detect and use the available API key(s).

### Basic Command

```bash
python main.py -run-id <RUN_ID> -model <MODEL>
```

### Command Line Arguments

#### Required Arguments
- **`-run-id <RUN_ID>`**: Required. The unique identifier for this pipeline run.
- **`-model <MODEL_NAME>`**: Specify the default model to use for all LLM steps.

#### Model Configuration
- **`-model-detect <MODEL_NAME>`**: Specify the model to use for the detection step.
- **`-model-annotate <MODEL_NAME>`**: Specify the model to use for the annotation step.
- **`-model-review <MODEL_NAME>`**: Specify the model to use for the review step.
- **`-model-targeted-annotate <MODEL_NAME>`**: Specify the model to use for the targeted annotation step.

#### Pipeline Control
- **`-skip-crawl`**: Skip the crawling steps (metadata and policy crawling).
- **`-skip-clean`**: Skip the cleaning step.
- **`-skip-detect`**: Skip the policy detection step.
- **`-skip-parse`**: Skip the parsing step.
- **`-skip-annotate`**: Skip the annotation step.
- **`-skip-review`**: Skip the review step.
- **`-skip-classify`**: Skip the classification step (only with `-two-step-annotation`).
- **`-skip-targeted-annotate`**: Skip the targeted annotation step (only with `-two-step-annotation`).

#### Two-Step Annotation Pipeline
- **`-two-step-annotation`**: Use two-step annotation pipeline (classify + targeted annotate).
- **`-annotated-folder <PATH>`**: Path to folder with manually annotated policies (evaluation mode).
- **`-confidence-threshold <FLOAT>`**: Confidence threshold for targeted annotation (default: 0.3).

#### RAG Configuration
- **`-no-rag`**: Disable RAG.
- **`-max-examples <INT>`**: Maximum examples per requirement (default: 2).
- **`-min-example-confidence <FLOAT>`**: Minimum confidence for examples (default: 0.8).

#### Annotation Scheme
- **`-opp-115`**: Use the OPP-115 privacy practice annotation scheme instead of the default GDPR-based scheme.

#### Batch Processing
- **`-batch-detect`**: Run detection step in batch mode.
- **`-batch-annotate`**: Run annotation step in batch mode.
- **`-batch-review`**: Run review step in batch mode.
- **`-batch-classify`**: Run classification step in batch mode (two-step pipeline).
- **`-batch-targeted-annotate`**: Run targeted annotation step in batch mode (two-step pipeline).

#### Performance Options
- **`-parallel-prompt`**: Enable parallel prompt processing (Ollama only).
- **`-crawl-retries <NUM>`**: Number of crawl retries (default: 2).
- **`-hostname <HOSTNAME>`**: Specify hostname for processing.
- **`-root-dir <PATH>`**: Specify root directory for output (default: ../../output).

#### Configuration and Modes
- **`--config <CONFIG_FILE>`**: Path to a JSON configuration file containing the above arguments.
- **`--websocket`**: Start WebSocket server for real-time pipeline control.
- **`--help`, `-h`**: Show help message.

### Example Commands

1. **Basic run:**

   ```bash
   python main.py -run-id 12345 -model gpt-4.1-nano
   ```

2. **Run with a specific package and model:**

   ```bash
   python main.py -run-id 12345 -pkg com.example.app -model gpt-4.1-nano
   ```

3. **Run with step-specific models and batch processing:**

   ```bash
   python main.py -run-id 12345 -model-detect gpt-gpt-4.1 -model-annotate gpt-4.1-nano -batch-detect -batch-annotate
   ```

4. **Two-step annotation pipeline:**

   ```bash
   python main.py -run-id 12345 -model gpt-4.1-nano -two-step-annotation
   ```

## Accessibility

The artifact is hosted on GitHub at https://github.com/tomcory/privacy-policy-annotator.

## Notes on Reusability

This artifact may be reused by researchers and practitioners interested in automating the annotation of privacy policies with GDPR transparency requirements. The modular design of the pipeline allows for easy adaptation to different LLM providers, models, and annotation schemes. The included crawler makes it easy to collect new privacy policies from the Google Play Store, and the cleaning and parsing steps ensure that the text is in a suitable format for annotation.

As-is, the pipeline supports the annotation scheme based on GDPR Articles 13 and 14 that is presented in the related paper, as well as the OPP-115 privacy practice annotation scheme. However, with minor modifications to the prompt templates and configuration files, the pipeline may be adapted to other annotation schemes.

The pipeline is compatible with multiple LLM providers, including OpenAI, Anthropic, DeepSeek, and Ollama. This allows users to choose the LLM provider that best fits their needs and budget. Additionally, the pipeline can be extended to support other LLM providers by implementing the necessary API calls in the `src/llm_connectors/` directory.

The dataset included in the artifact, the "GDPR Transparency 200" dataset, can be used as a benchmark for evaluating the performance of other annotation methods or models. Researchers can also use the dataset to train and fine-tune their own models for privacy policy annotation.

Beyond privacy policy annotation, the modular design of the pipeline can be adapted to other text annotation tasks that require compliance with specific legal or regulatory requirements. By modifying the prompt templates and configuration files, users can tailor the pipeline to annotate documents in other domains, such as terms of service agreements, data processing agreements, or other legal texts.